name: "Pre/Post Operation"
description: "Collect workflow inputs, logs, and generate audit reports"
inputs:
  token:
    required: true
  run_id:
    required: true
  repository:
    required: true
  mode:
    required: true
  job_url:
    required: false
  input_json:
    required: false
  pat_token:
    required: false
    description: PAT token for log access (post-op only)

outputs:
  metadata:
    description: Metadata (inputs, timestamps)
  audit:
    description: Structured audit JSON (post-op only)

runs:
  using: "composite"
  steps:
    - name: Create workspace
      shell: bash
      run: mkdir -p metadata logs audit

    - name: Generate Pre/Post Metadata
      shell: bash
      run: |
        MODE="${{ inputs.mode }}"
        JOB_URL="${{ inputs.job_url }}"
        INPUT_JSON='${{ inputs.input_json }}'

        # Parse dynamic inputs
        DYNAMIC_INPUTS="{"
        first=true
        for key in $(echo "$INPUT_JSON" | jq -r 'keys[]'); do
          value=$(echo "$INPUT_JSON" | jq -r --arg k "$key" '.[$k]')
          if [ "$first" = true ]; then
            first=false
          else
            DYNAMIC_INPUTS+=", "
          fi
          DYNAMIC_INPUTS+="\"$key\": \"$value\""
        done
        DYNAMIC_INPUTS+="}"

        if [[ "$MODE" == "pre-op" ]]; then
          START_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          METADATA=$(jq -n \
            --arg start_time "$START_TIME" \
            --arg job_url "$JOB_URL" \
            --argjson inputs "$DYNAMIC_INPUTS" \
            '{phase: "pre-op", start_time: $start_time, job_url: $job_url, inputs: $inputs}')

        elif [[ "$MODE" == "post-op" ]]; then
          echo "⏬ Fetching logs for run ${{ inputs.run_id }}"
          curl -sSL -H "Authorization: token ${{ inputs.pat_token }}" \
            -o logs/full_logs.zip \
            https://api.github.com/repos/${{ inputs.repository }}/actions/runs/${{ inputs.run_id }}/logs

          if file logs/full_logs.zip | grep -q 'Zip archive data'; then
            unzip -qq logs/full_logs.zip -d logs/
            echo "✅ Logs unzipped."
          else
            echo "❌ Log ZIP is invalid."
            exit 1
          fi

          END_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          START_TIME=$(jq -r '.start_time' metadata/metadata.json 2>/dev/null || echo "$END_TIME")
          DURATION=$(($(date -d "$END_TIME" +%s) - $(date -d "$START_TIME" +%s)))

          # Extract log summaries
          ERROR_FILE=$(find logs -type f -name '*.txt' -exec grep -li 'error' {} + | head -n 1)
          if [ -n "$ERROR_FILE" ]; then
            STDERR=$(grep -i 'error' "$ERROR_FILE" | head -n 10 | jq -Rs .)
          else
            STDERR="\"No errors found\""
          fi

          STDOUT_FILE=$(find logs -type f -name '*.txt' | head -n 1)
          if [ -n "$STDOUT_FILE" ]; then
            STDOUT=$(head -n 50 "$STDOUT_FILE" | jq -Rs .)
          else
            STDOUT="\"No stdout available\""
          fi

          # Audit JSON
          AUDIT=$(jq -n \
            --arg job_url "$JOB_URL" \
            --arg start_time "$START_TIME" \
            --arg end_time "$END_TIME" \
            --argjson duration $DURATION \
            --argjson inputs "$DYNAMIC_INPUTS" \
            --argjson stderr "$STDERR" \
            --argjson stdout "$STDOUT" \
            '{
              job_url: $job_url,
              start_time: $start_time,
              end_time: $end_time,
              duration_seconds: $duration,
              inputs: $inputs,
              logs: {
                stderr_preview: $stderr,
                stdout_preview: $stdout
              }
            }')

          echo "$AUDIT" > audit/workflow-a-audit-report.json
        fi

        METADATA_SINGLE_LINE=$(echo "$METADATA" | jq -c '.')
        echo "metadata=$METADATA_SINGLE_LINE" >> $GITHUB_OUTPUT
        echo "$METADATA_SINGLE_LINE" > metadata/metadata.json
